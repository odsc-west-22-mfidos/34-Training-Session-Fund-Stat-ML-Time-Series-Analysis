{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font size=\"6\"><b><center> Section 3</font></center>\n",
    "<br>\n",
    "<font size=\"6\"><b><center> Practical Aspects of Building Deep Learning Models </font></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this example, we will illustrate the comparison between training and validation losses and regularization techniques using dropout and L2-norm regularization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notations for Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T15:09:37.958331Z",
     "start_time": "2019-04-06T15:09:37.950241Z"
    }
   },
   "source": [
    "Regularized objective function:\n",
    "\n",
    "$ C = C_0 + \\text{Penalty Term} $\n",
    "\n",
    "where $C_0$ is the unregularized objective function\n",
    "\n",
    "$L^2$ norm penalty term typically take the form of $ \\frac{1}{2} ||w||^2_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation by equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs to hidden layer 1**\n",
    "\n",
    "$z_1(\\mathbf{x}; \\mathbf{w_1},b_1) = \\sum_{j=1}^4 w_{1,j}^{(1)} x_j + b_1^{(1)}$\n",
    "\n",
    "\n",
    "$z_2(\\mathbf{x}; \\mathbf{w_2},b_2) = \\sum_{j=1}^4 w_{2,j}^{(1)} x_j + b_2^{(1)}$\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "$z_6(\\mathbf{x}; \\mathbf{w_6},b_6) = \\sum_{j=1}^4 w_{6,j}^{(1)} x_j + b_6^{(1)}$\n",
    "\n",
    "where $j=1,2,3,4$ (in this example) is the index for the inputs\n",
    "\n",
    "$h_k(\\mathbf{x}; \\mathbf{w_k},b_k) = g_1(z_k)$ where $k=1,2,\\dots,6$ is the index for the hidden units\n",
    "\n",
    "\n",
    "**Hidden layer 1 to output**\n",
    "\n",
    "$y_1 = g_2 \\left( \\sum_{k=1}^6 w_{1,k}^{(2)} + b_1^{(2)} \\right)$\n",
    "\n",
    "$y_2 = g_2 \\left( \\sum_{k=1}^6 w_{2,k}^{(2)} + b_2^{(2)} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential layerwise architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First layer:\n",
    "$$ \\mathbf{h}^{(1)} = g^{(1)} \\left(\\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}  \\right) $$\n",
    "\n",
    "Second layer:\n",
    "$$ \\mathbf{h}^{(2)} = g^{(2)} \\left(\\mathbf{W}^{(2)T} \\mathbf{h}^{(1)} + \\mathbf{b}^{(2)}  \\right) $$\n",
    "\n",
    "\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "\n",
    "$l^{th}$ layer:\n",
    "$$ \\mathbf{h}^{(l)} = g^{(l)} \\left(\\mathbf{W}^{(l)T} \\mathbf{h}^{(l-1)} + \\mathbf{b}^{(l)}  \\right) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Feedforward Network Without Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is related to the input using the following function\n",
    "\n",
    "$$y_i = 3x_{i,1} + x^2 exp(x_{i,1}) + \\epsilon_i$$\n",
    "\n",
    "where $\\epsilon$ is an independently and identically distributed (i.i.d.) random variable and $i = 1,2,\\dots,n$ is an index of examples (or observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:45.835205Z",
     "start_time": "2019-04-11T03:10:43.675905Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "n = 200 # number of examples (or observations)\n",
    "\n",
    "# Generate a set of n random numbers from a standard normal distribution\n",
    "epsilon = np.random.randn(n)\n",
    "\n",
    "# Generate a set of n random numbers from a uniform[0,1] distribution; name it x1\n",
    "# and create another variable, which we name x2, from x1\n",
    "x1 = np.random.uniform(0,1,n)\n",
    "x2 = 1. / (1. + np.exp(-np.power(x1,3))) + 0.5*epsilon\n",
    "x3 = np.random.randn(n)\n",
    "\n",
    "X = pd.DataFrame({'x1':x1, 'x2':x2})\n",
    "\n",
    "# Create the data generating mechanism\n",
    "y = 3*x1 + np.power(x1,2)*np.exp(x1) + 0.8*x2 + 0.5*x3 + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:45.897007Z",
     "start_time": "2019-04-11T03:10:45.837374Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:45.938411Z",
     "start_time": "2019-04-11T03:10:45.899566Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.describe().T.round(4), \"\\n\")\n",
    "print(pd.DataFrame({'y':y_train}).describe().T.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:45.954432Z",
     "start_time": "2019-04-11T03:10:45.940933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation between x1 and x2 in the training set\n",
    "np.corrcoef(X_train.iloc[:,0], X_train.iloc[:,1])[0][1].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:46.989883Z",
     "start_time": "2019-04-11T03:10:45.957582Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.hist(y_train)\n",
    "plt.title(\"y (Training Set)\")\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.scatter(X_train.iloc[:,0], y_train)\n",
    "plt.title(\"y vs x1 (Training Set)\")\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.scatter(X_train.iloc[:,1], y_train)\n",
    "plt.title(\"y vs x2 (Training Set)\")\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.hist(X_train.iloc[:,0])\n",
    "plt.title(\"x1 (Training Set)\")\n",
    "\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.scatter(X_train.iloc[:,0], X_train.iloc[:,1])\n",
    "plt.title(\"x2 vs x1 (Training Set)\")\n",
    "\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.hist(X_train.iloc[:,1])\n",
    "plt.title(\"x2 (Training Set)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note: Before training, `numpy array` and `pandas dataframe` need to be converted to `PyTorch's tensors`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.223917Z",
     "start_time": "2019-04-11T03:10:46.992792Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert numpy array to tensor in shape of input size\n",
    "import torch \n",
    "\n",
    "X_train_ts = torch.from_numpy(X_train.values.reshape(-1,2)).float()\n",
    "y_train_ts = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "\n",
    "X_test_ts = torch.from_numpy(X_test.values.reshape(-1,2)).float()\n",
    "y_test_ts = torch.from_numpy(y_test.reshape(-1,1)).float() # y_test is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.234580Z",
     "start_time": "2019-04-11T03:10:47.226455Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_train_ts is of %s type\" %type(X_train_ts))\n",
    "print(\"y_train_ts is of %s type\" %type(y_train_ts))\n",
    "print(\"X_test_ts is of %s type\" %type(X_test_ts))\n",
    "print(\"y_test_ts is of %s type\" %type(y_test_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.250339Z",
     "start_time": "2019-04-11T03:10:47.237666Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_ts.shape)\n",
    "print(y_train_ts.shape)\n",
    "print(X_test_ts.shape)\n",
    "print(y_test_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.265520Z",
     "start_time": "2019-04-11T03:10:47.254969Z"
    }
   },
   "outputs": [],
   "source": [
    "# First 5 rows of tensor X\n",
    "print(\"First 5 rows of tensor X_train_ts\", \"\\n\",  X_train_ts[:5], \"\\n\")\n",
    "print(\"First 5 rows of tensor y_train_ts\", \"\\n\",  y_train_ts[:5], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feed-forward network with 1 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.277111Z",
     "start_time": "2019-04-11T03:10:47.268471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's confirm the dimensions of the inputs and outpu\n",
    "print(\"train_size: \", len(X_train_ts), \"\\n\")\n",
    "print(\"X shape:\", X_train_ts.shape, \"\\n\")\n",
    "print(\"y shape:\", y_train_ts.shape, \"\\n\")\n",
    "print(X_train_ts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.290824Z",
     "start_time": "2019-04-11T03:10:47.279901Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ffNet(nn.Module):\n",
    "    \"\"\"\n",
    "    D_in: input dimension\n",
    "    D_h1: dimension of hidden layer 1\n",
    "    D_out: output dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, D_in, D_h1, D_h2, D_out):\n",
    "        super(ffNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, D_h1)\n",
    "        self.linear2 = torch.nn.Linear(D_h1, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.linear1(x))\n",
    "        y_pred = self.linear2(h1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model by instantiating the class defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.299700Z",
     "start_time": "2019-04-11T03:10:47.293785Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.310647Z",
     "start_time": "2019-04-11T03:10:47.303388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the model by instantiating the class defined above\n",
    "D_in = X_train.shape[1]\n",
    "D_h1, D_h2 = 8,4\n",
    "D_out = 1\n",
    "\n",
    "ffnet = ffNet(D_in, D_h1, D_h2, D_out)\n",
    "print(ffnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:47.318512Z",
     "start_time": "2019-04-11T03:10:47.313929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), lr=0.01)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:49.535855Z",
     "start_time": "2019-04-11T03:10:47.321226Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_data = X_train_ts\n",
    "y_data = y_train_ts\n",
    "\n",
    "X_data_val = X_test_ts\n",
    "y_data_val = y_test_ts\n",
    "\n",
    "n_epoch = 500\n",
    "\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    y_pred = ffnet(X_data)    \n",
    "    epoch_loss_train = loss_func(y_pred, y_data) \n",
    "    \n",
    "    y_pred_val = ffnet(X_data_val)\n",
    "    epoch_loss_val = loss_func(y_pred_val, y_data_val)     \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss_train.backward()        \n",
    "    optimizer.step()       \n",
    "    \n",
    "    train_loss.append(epoch_loss_train)\n",
    "    val_loss.append(epoch_loss_val)\n",
    "    \n",
    "    #if epoch <= 5 or epoch % 100 == 0:\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}, Training loss {}, Validation loss {}'.format(epoch, round(float(epoch_loss_train),4), round(float(epoch_loss_val),4)))\n",
    "        \n",
    "        #plt.cla()\n",
    "        \n",
    "        fig = plt.figure(figsize=(16,6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_train.iloc[:,0], y_train, label=\"actual\")\n",
    "        plt.scatter(X_train.iloc[:,0], y_pred.detach().numpy(), label=\"prediction\")\n",
    "        plt.title(\"Training\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(X_test.iloc[:,0], y_test, label=\"actual\")\n",
    "        plt.scatter(X_test.iloc[:,0], y_pred_val.detach().numpy(),label=\"prediction\")\n",
    "        plt.title(\"Validation\")\n",
    "        plt.legend()\n",
    "        \n",
    "        #plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 10, 'color':  'red'})\n",
    "        #plt.pause(0.1)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:49.847213Z",
     "start_time": "2019-04-11T03:10:49.538950Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss,'b',label = 'training loss')\n",
    "plt.plot(range(1,len(val_loss)+1),val_loss,'g',label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Feedforward Network With a Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:49.862640Z",
     "start_time": "2019-04-11T03:10:49.850775Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ffNet(nn.Module):\n",
    "    \"\"\"\n",
    "    D_in: input dimension\n",
    "    D_h1: dimension of hidden layer 1\n",
    "    D_out: output dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, D_in, D_h1, D_h2, D_out):\n",
    "        super(ffNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, D_h1)\n",
    "        self.linear1_drop = torch.nn.Dropout(p=0.8)\n",
    "        self.linear2 = torch.nn.Linear(D_h1, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.linear1(x))\n",
    "        y_pred = self.linear2(h1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model by instantiating the class defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:49.875428Z",
     "start_time": "2019-04-11T03:10:49.866520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the model by instantiating the class defined above\n",
    "D_in = X_train.shape[1]\n",
    "D_h1, D_h2 = 8,4\n",
    "D_out = 1\n",
    "\n",
    "ffnet = ffNet(D_in, D_h1, D_h2, D_out)\n",
    "print(ffnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:49.884274Z",
     "start_time": "2019-04-11T03:10:49.878488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "\n",
    "#optimizer = torch.optim.SGD(ffnet.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), lr=0.01)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:52.557954Z",
     "start_time": "2019-04-11T03:10:49.889285Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_data = X_train_ts\n",
    "y_data = y_train_ts\n",
    "\n",
    "X_data_val = X_test_ts\n",
    "y_data_val = y_test_ts\n",
    "\n",
    "n_epoch = 500\n",
    "\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    y_pred = ffnet(X_data)    \n",
    "    epoch_loss_train = loss_func(y_pred, y_data) \n",
    "    \n",
    "    y_pred_val = ffnet(X_data_val)\n",
    "    epoch_loss_val = loss_func(y_pred_val, y_data_val)     \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss_train.backward()        \n",
    "    optimizer.step()       \n",
    "    \n",
    "    train_loss.append(epoch_loss_train)\n",
    "    val_loss.append(epoch_loss_val)\n",
    "    \n",
    "    #if epoch <= 5 or epoch % 100 == 0:\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}, Training loss {}, Validation loss {}'.format(epoch, round(float(epoch_loss_train),4), round(float(epoch_loss_val),4)))\n",
    "        \n",
    "        #plt.cla()\n",
    "        \n",
    "        fig = plt.figure(figsize=(16,6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_train.iloc[:,0], y_train, label=\"actual\")\n",
    "        plt.scatter(X_train.iloc[:,0], y_pred.detach().numpy(), label=\"prediction\")\n",
    "        plt.title(\"Training\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(X_test.iloc[:,0], y_test, label=\"actual\")\n",
    "        plt.scatter(X_test.iloc[:,0], y_pred_val.detach().numpy(),label=\"prediction\")\n",
    "        plt.title(\"Validation\")\n",
    "        plt.legend()\n",
    "        \n",
    "        #plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 10, 'color':  'red'})\n",
    "        #plt.pause(0.1)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:10:52.848996Z",
     "start_time": "2019-04-11T03:10:52.560684Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss,'b',label = 'training loss')\n",
    "plt.plot(range(1,len(val_loss)+1),val_loss,'g',label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will replicate the above exercise with a different simulated dataset. \n",
    "\n",
    "  - You will simply run the codes to simulate the data and conduct some descriptive analysis.\n",
    "\n",
    "  - Then, you will design a network, instantiate it, run the training loop, and evaluate the model by plotting computing the loss of the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:16:46.617514Z",
     "start_time": "2019-04-11T03:16:46.602265Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "n = 200 # number of examples (or observations)\n",
    "\n",
    "# Generate a set of n random numbers from a standard normal distribution\n",
    "epsilon = np.random.randn(n)\n",
    "\n",
    "# Generate a set of n random numbers from a uniform[0,1] distribution; name it x1\n",
    "# and create another variable, which we name x2, from x1\n",
    "x1 = np.random.uniform(0,1,n)\n",
    "\n",
    "X = pd.DataFrame({'x1':x1})\n",
    "\n",
    "# Create the data generating mechanism\n",
    "y = 1.5*x1 + np.power(x1,3)*np.exp(x1) + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:16:54.276737Z",
     "start_time": "2019-04-11T03:16:54.271811Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:16:55.938611Z",
     "start_time": "2019-04-11T03:16:55.912778Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.describe().T.round(4), \"\\n\")\n",
    "print(pd.DataFrame({'y':y_train}).describe().T.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:18:03.534505Z",
     "start_time": "2019-04-11T03:18:02.739133Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(y_train)\n",
    "plt.title(\"y (Training Set)\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(X_train.iloc[:,0], y_train)\n",
    "plt.title(\"y vs x1 (Training Set)\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(X_train.iloc[:,0])\n",
    "plt.title(\"x1 (Training Set)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note: Before training, `numpy array` and `pandas dataframe` need to be converted to `PyTorch's tensors`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:19:11.141327Z",
     "start_time": "2019-04-11T03:19:11.134477Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert numpy array to tensor in shape of input size\n",
    "import torch \n",
    "\n",
    "X_train_ts = torch.from_numpy(X_train.values.reshape(-1,1)).float()\n",
    "y_train_ts = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "\n",
    "X_test_ts = torch.from_numpy(X_test.values.reshape(-1,1)).float()\n",
    "y_test_ts = torch.from_numpy(y_test.reshape(-1,1)).float() # y_test is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:19:11.587381Z",
     "start_time": "2019-04-11T03:19:11.579680Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_train_ts is of %s type\" %type(X_train_ts))\n",
    "print(\"y_train_ts is of %s type\" %type(y_train_ts))\n",
    "print(\"X_test_ts is of %s type\" %type(X_test_ts))\n",
    "print(\"y_test_ts is of %s type\" %type(y_test_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Do the shape of these tensors make sense to you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:19:12.467957Z",
     "start_time": "2019-04-11T03:19:12.461054Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_ts.shape)\n",
    "print(y_train_ts.shape)\n",
    "print(X_test_ts.shape)\n",
    "print(y_test_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feed-forward network with 1 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Do the shape in the following tensors confirm your expectation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:22:37.613546Z",
     "start_time": "2019-04-11T03:22:37.605072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's confirm the dimensions of the inputs and outpu\n",
    "print(\"train_size: \", len(X_train_ts), \"\\n\")\n",
    "print(\"X shape:\", X_train_ts.shape, \"\\n\")\n",
    "print(\"y shape:\", y_train_ts.shape, \"\\n\")\n",
    "print(X_train_ts.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following code to design a one hidden-layer feedforward network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:22:51.808779Z",
     "start_time": "2019-04-11T03:22:51.797935Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ffNet(nn.Module):\n",
    "    \"\"\"\n",
    "    D_in: input dimension\n",
    "    D_h1: dimension of hidden layer 1\n",
    "    D_out: output dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, D_in, D_h1, D_out):\n",
    "        super(ffNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, D_h1)\n",
    "        self.linear2 = torch.nn.Linear(D_h1, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.linear1(x))\n",
    "        y_pred = self.linear2(h1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model by instantiating the class defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:22:57.818421Z",
     "start_time": "2019-04-11T03:22:57.812728Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose your parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:23:14.005390Z",
     "start_time": "2019-04-11T03:23:13.998497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the model by instantiating the class defined above\n",
    "D_in  = 0 # Replace 0 with your code here\n",
    "D_h1  = 0 # Replace 0 with an integer\n",
    "D_out = 0 # Replace 0 with the dimension of the output\n",
    "\n",
    "ffnet = ffNet(D_in, D_h1, D_out)\n",
    "print(ffnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can specify the learning rate if you want.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:23:18.073980Z",
     "start_time": "2019-04-11T03:23:18.067792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "\n",
    "learning_rate = 0.01 #You can specify the learning rate\n",
    "\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose the number of epochs for your training**\n",
    "**2. Fill in some details in the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:23:49.190594Z",
     "start_time": "2019-04-11T03:23:43.707774Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_data = X_train_ts\n",
    "y_data = y_train_ts\n",
    "\n",
    "X_data_val = X_test_ts\n",
    "y_data_val = y_test_ts\n",
    "\n",
    "n_epoch = 0 # Choose the number of epochs for your training\n",
    "\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    y_pred = ffnet(A) # Fill in the blank by replacing A   \n",
    "    epoch_loss_train = loss_func(y_pred, y_data) \n",
    "    \n",
    "    y_pred_val = ffnet(B) # Fill in the blank by replacing B\n",
    "    epoch_loss_val = loss_func(C, D) # Fill in the blank by replacing C and D\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss_train.backward()        \n",
    "    optimizer.step()       \n",
    "    \n",
    "    train_loss.append(epoch_loss_train)\n",
    "    val_loss.append(epoch_loss_val)\n",
    "    \n",
    "    #if epoch <= 5 or epoch % 100 == 0:\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}, Training loss {}, Validation loss {}'.format(epoch, round(float(epoch_loss_train),4), round(float(epoch_loss_val),4)))\n",
    "                \n",
    "        fig = plt.figure(figsize=(16,6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_train.iloc[:,0], y_train, label=\"actual\")\n",
    "        plt.scatter(X_train.iloc[:,0], y_pred.detach().numpy(), label=\"prediction\")\n",
    "        plt.title(\"Training\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(X_test.iloc[:,0], y_test, label=\"actual\")\n",
    "        plt.scatter(X_test.iloc[:,0], y_pred_val.detach().numpy(),label=\"prediction\")\n",
    "        plt.title(\"Validation\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:23:56.504952Z",
     "start_time": "2019-04-11T03:23:56.146179Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss,'b',label = 'training loss')\n",
    "plt.plot(range(1,len(val_loss)+1),val_loss,'g',label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Network With a Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the dropout layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:24:32.979044Z",
     "start_time": "2019-04-11T03:24:32.961831Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ffNet(nn.Module):\n",
    "    \"\"\"\n",
    "    D_in: input dimension\n",
    "    D_h1: dimension of hidden layer 1\n",
    "    D_out: output dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, D_in, D_h1, D_out):\n",
    "        super(ffNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, D_h1)\n",
    "        self.linear1_drop = DROPOUT_LAYER # Specify the dropout layer by replacing DROPOUT_LAYER\n",
    "        self.linear2 = torch.nn.Linear(D_h1, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.linear1(x))\n",
    "        y_pred = self.linear2(h1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model by instantiating the class defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:24:46.707041Z",
     "start_time": "2019-04-11T03:24:46.700576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the model by instantiating the class defined above\n",
    "D_in  = 0 # Specify D_in\n",
    "D_h1  = 0 # Specify D_h1\n",
    "D_out = 0 # Specify D_out\n",
    "\n",
    "ffnet = ffNet(D_in, D_h1, D_out)\n",
    "print(ffnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the learning rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:24:57.014872Z",
     "start_time": "2019-04-11T03:24:57.009627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), lr=1e-6) # Change the learning rate \n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:25:11.970793Z",
     "start_time": "2019-04-11T03:25:06.273365Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_data = X_train_ts\n",
    "y_data = y_train_ts\n",
    "\n",
    "X_data_val = X_test_ts\n",
    "y_data_val = y_test_ts\n",
    "\n",
    "n_epoch = 1000\n",
    "\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    y_pred = ffnet(X_data)    \n",
    "    epoch_loss_train = loss_func(y_pred, y_data) \n",
    "    \n",
    "    y_pred_val = ffnet(X_data_val)\n",
    "    epoch_loss_val = loss_func(y_pred_val, y_data_val)     \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss_train.backward()        \n",
    "    optimizer.step()       \n",
    "    \n",
    "    train_loss.append(epoch_loss_train)\n",
    "    val_loss.append(epoch_loss_val)\n",
    "    \n",
    "    #if epoch <= 5 or epoch % 100 == 0:\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}, Training loss {}, Validation loss {}'.format(epoch, round(float(epoch_loss_train),4), round(float(epoch_loss_val),4)))\n",
    "        \n",
    "        #plt.cla()\n",
    "        \n",
    "        fig = plt.figure(figsize=(16,6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_train.iloc[:,0], y_train, label=\"actual\")\n",
    "        plt.scatter(X_train.iloc[:,0], y_pred.detach().numpy(), label=\"prediction\")\n",
    "        plt.title(\"Training\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(X_test.iloc[:,0], y_test, label=\"actual\")\n",
    "        plt.scatter(X_test.iloc[:,0], y_pred_val.detach().numpy(),label=\"prediction\")\n",
    "        plt.title(\"Validation\")\n",
    "        plt.legend()\n",
    "        \n",
    "        #plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 10, 'color':  'red'})\n",
    "        #plt.pause(0.1)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:25:23.339872Z",
     "start_time": "2019-04-11T03:25:22.998287Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss,'b',label = 'training loss')\n",
    "plt.plot(range(1,len(val_loss)+1),val_loss,'g',label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
